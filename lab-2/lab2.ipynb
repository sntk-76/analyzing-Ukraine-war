{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Install and import necessary libraries :  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\sina tavakoli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\sina tavakoli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\sina tavakoli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sina tavakoli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in c:\\users\\sina tavakoli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\sina tavakoli\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
            "Requirement already satisfied: networkx in c:\\users\\sina tavakoli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\sina\n",
            "[nltk_data]     tavakoli\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\sina tavakoli\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\sina\n",
            "[nltk_data]     tavakoli\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to C:\\Users\\sina\n",
            "[nltk_data]     tavakoli\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package words to C:\\Users\\sina\n",
            "[nltk_data]     tavakoli\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to C:\\Users\\sina\n",
            "[nltk_data]     tavakoli\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     C:\\Users\\sina tavakoli\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "import itertools\n",
        "import networkx as nx\n",
        "\n",
        "nltk.download('punkt')  # Required for wordpunct_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')  # POS tagger\n",
        "nltk.download('wordnet')  # WordNet for lemmatization\n",
        "nltk.download('omw-1.4')  # WordNet's dependencies\n",
        "nltk.download('words')  # For the word corpus\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "words = set(nltk.corpus.words.words())\n",
        "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "tweet_tokenizer = nltk.TweetTokenizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Importing data : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'subreddit', 'selftext', 'author_fullname', 'title',\n",
              "       'upvote_ratio', 'ups', 'created', 'created_utc', 'num_comments',\n",
              "       'author', 'id'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_df = pd.DataFrame(pd.read_csv('D:/other/job/students_project/network_science/TA project/analyzing-Ukraine-war/ukrainewar_full.csv'))\n",
        "tweets_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "AZYiG40aumbk"
      },
      "outputs": [],
      "source": [
        "tweets_filtered = tweets_df.copy() #it's a good idea to work on the copy of original dataframe, so we can always go back to it if we mess something up\n",
        "column_list = [\"id\",\"author\",\"subreddit\",\"title\",\"selftext\", \"upvote_ratio\",\"num_comments\"]\n",
        "tweets_filtered = tweets_filtered[column_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "qQ90m-FpxM9N"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>selftext</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>num_comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12aw2q2</td>\n",
              "      <td>ModeratorsOfEurope</td>\n",
              "      <td>europe</td>\n",
              "      <td>War in Ukraine Megathread LIII</td>\n",
              "      <td>\\nThis megathread is meant for discussion of t...</td>\n",
              "      <td>0.95</td>\n",
              "      <td>8232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10eps9y</td>\n",
              "      <td>ModeratorsOfEurope</td>\n",
              "      <td>europe</td>\n",
              "      <td>War in Ukraine Megathread L</td>\n",
              "      <td>This megathread is meant for discussion of the...</td>\n",
              "      <td>0.96</td>\n",
              "      <td>9524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119wltg</td>\n",
              "      <td>ModeratorsOfEurope</td>\n",
              "      <td>europe</td>\n",
              "      <td>War in Ukraine Megathread LII</td>\n",
              "      <td>This is a special megathread. **One year ago, ...</td>\n",
              "      <td>0.97</td>\n",
              "      <td>8276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>z3mb0m</td>\n",
              "      <td>BackgroundGold3503</td>\n",
              "      <td>Cursedgunimages</td>\n",
              "      <td>Wtf</td>\n",
              "      <td>What the hell is this russian creation !!  #uk...</td>\n",
              "      <td>0.97</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14oijq5</td>\n",
              "      <td>ModeratorsOfEurope</td>\n",
              "      <td>europe</td>\n",
              "      <td>War in Ukraine Megathread LV (55)</td>\n",
              "      <td>\\nThis megathread is meant for discussion of t...</td>\n",
              "      <td>0.94</td>\n",
              "      <td>4457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4132</th>\n",
              "      <td>1182qiw</td>\n",
              "      <td>mdkss12</td>\n",
              "      <td>caps</td>\n",
              "      <td>Lucky Guess - Game 59: vs DET</td>\n",
              "      <td>This team without Ovi is *rough*. we'll see ho...</td>\n",
              "      <td>0.75</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4133</th>\n",
              "      <td>zy6szr</td>\n",
              "      <td>mdkss12</td>\n",
              "      <td>caps</td>\n",
              "      <td>Lucky Guess - Game 37: vs OTT</td>\n",
              "      <td>Shutout! you love to see it, especially in a d...</td>\n",
              "      <td>0.67</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4134</th>\n",
              "      <td>12hh318</td>\n",
              "      <td>mdkss12</td>\n",
              "      <td>caps</td>\n",
              "      <td>Lucky Guess - Game 80: vs NYI - Blunder for Be...</td>\n",
              "      <td>Keep on losing and try to move up the draft lo...</td>\n",
              "      <td>0.64</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4135</th>\n",
              "      <td>11dlwx9</td>\n",
              "      <td>liberty_ukraine</td>\n",
              "      <td>u_liberty_ukraine</td>\n",
              "      <td>Liberty Ukraine in Action!</td>\n",
              "      <td>\\n\\nLiberty Ukraine in Action! Thank you for ...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4136</th>\n",
              "      <td>11269ca</td>\n",
              "      <td>mdkss12</td>\n",
              "      <td>caps</td>\n",
              "      <td>Lucky Guess - Game 56: vs CAR</td>\n",
              "      <td>Beat the best team in the league, then lose to...</td>\n",
              "      <td>0.67</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4137 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id              author          subreddit  \\\n",
              "0     12aw2q2  ModeratorsOfEurope             europe   \n",
              "1     10eps9y  ModeratorsOfEurope             europe   \n",
              "2     119wltg  ModeratorsOfEurope             europe   \n",
              "3      z3mb0m  BackgroundGold3503    Cursedgunimages   \n",
              "4     14oijq5  ModeratorsOfEurope             europe   \n",
              "...       ...                 ...                ...   \n",
              "4132  1182qiw             mdkss12               caps   \n",
              "4133   zy6szr             mdkss12               caps   \n",
              "4134  12hh318             mdkss12               caps   \n",
              "4135  11dlwx9     liberty_ukraine  u_liberty_ukraine   \n",
              "4136  11269ca             mdkss12               caps   \n",
              "\n",
              "                                                  title  \\\n",
              "0                        War in Ukraine Megathread LIII   \n",
              "1                           War in Ukraine Megathread L   \n",
              "2                         War in Ukraine Megathread LII   \n",
              "3                                                   Wtf   \n",
              "4                     War in Ukraine Megathread LV (55)   \n",
              "...                                                 ...   \n",
              "4132                      Lucky Guess - Game 59: vs DET   \n",
              "4133                      Lucky Guess - Game 37: vs OTT   \n",
              "4134  Lucky Guess - Game 80: vs NYI - Blunder for Be...   \n",
              "4135                         Liberty Ukraine in Action!   \n",
              "4136                      Lucky Guess - Game 56: vs CAR   \n",
              "\n",
              "                                               selftext  upvote_ratio  \\\n",
              "0     \\nThis megathread is meant for discussion of t...          0.95   \n",
              "1     This megathread is meant for discussion of the...          0.96   \n",
              "2     This is a special megathread. **One year ago, ...          0.97   \n",
              "3     What the hell is this russian creation !!  #uk...          0.97   \n",
              "4     \\nThis megathread is meant for discussion of t...          0.94   \n",
              "...                                                 ...           ...   \n",
              "4132  This team without Ovi is *rough*. we'll see ho...          0.75   \n",
              "4133  Shutout! you love to see it, especially in a d...          0.67   \n",
              "4134  Keep on losing and try to move up the draft lo...          0.64   \n",
              "4135   \\n\\nLiberty Ukraine in Action! Thank you for ...          1.00   \n",
              "4136  Beat the best team in the league, then lose to...          0.67   \n",
              "\n",
              "      num_comments  \n",
              "0             8232  \n",
              "1             9524  \n",
              "2             8276  \n",
              "3               15  \n",
              "4             4457  \n",
              "...            ...  \n",
              "4132            32  \n",
              "4133            42  \n",
              "4134            29  \n",
              "4135             0  \n",
              "4136            38  \n",
              "\n",
              "[4137 rows x 7 columns]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_filtered.dropna(inplace=True)\n",
        "tweets_filtered.reset_index(inplace=True,drop=True)\n",
        "tweets_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPgzBUJj0SZU"
      },
      "source": [
        "# 3. Cleaning text : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Z8Nrv5jv1e5W"
      },
      "outputs": [],
      "source": [
        "def cleaner(tweet):\n",
        "    try:\n",
        "        tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) # remove mentions\n",
        "        tweet = re.sub(\"#[A-Za-z0-9]+\", \"\",tweet) # remove hashtags\n",
        "        tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) # remove http links\n",
        "        tweet = \" \".join(tweet.split())\n",
        "        tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) if w.lower() in words and not w.lower() in stop_words)  # remove stop words\n",
        "        lemma_function = WordNetLemmatizer()\n",
        "        tweet = \" \".join(lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in nltk.pos_tag(nltk.wordpunct_tokenize(tweet))) #lemmatize\n",
        "        tweet = str.lower(tweet) #to lowercase\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing tweet: {tweet}, error: {e}\")\n",
        "        return \"\"\n",
        "    return tweet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "fEhs-tyy2naZ"
      },
      "outputs": [],
      "source": [
        "tweets_filtered[\"clean_text\"] = tweets_filtered[\"selftext\"].map(cleaner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "TPcEWnQuco41"
      },
      "outputs": [],
      "source": [
        "tweets_filtered\n",
        "tweets_filtered.to_csv(\"D:/other/Mannheim university/Data Mining/final project/additional files/text_filtered.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Extracting words : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "d8paxTEfe1se"
      },
      "outputs": [],
      "source": [
        "tweets_filtered.loc[tweets_filtered[\"clean_text\"].isnull(),\"clean_text\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "zlHlvVlua3bq"
      },
      "outputs": [],
      "source": [
        "unique_words = {}\n",
        "\n",
        "for idx, row in tweets_filtered.iterrows():\n",
        "  if row[\"clean_text\"] != \"\":\n",
        "    for word in tweet_tokenizer.tokenize(row[\"clean_text\"]):\n",
        "      unique_words.setdefault(word,0)\n",
        "      unique_words[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "IgMjaVe-a3bt"
      },
      "outputs": [],
      "source": [
        "uw_df = pd.DataFrame.from_dict(unique_words, orient='index').reset_index()\n",
        "uw_df.rename(columns = {'index':'Word', 0:'Count'}, inplace=True)\n",
        "uw_df.sort_values(by=['Count'], ascending=False, inplace=True)\n",
        "uw_df = uw_df.reset_index().drop(columns=[\"index\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "eZW8-9gYbHJk"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>team</td>\n",
              "      <td>9675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go</td>\n",
              "      <td>7579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>scorer</td>\n",
              "      <td>6072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>game</td>\n",
              "      <td>5574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>season</td>\n",
              "      <td>5530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1078</th>\n",
              "      <td>criticism</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1079</th>\n",
              "      <td>praise</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1080</th>\n",
              "      <td>issue</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081</th>\n",
              "      <td>united</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082</th>\n",
              "      <td>sufficient</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1083 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Word  Count\n",
              "0           team   9675\n",
              "1             go   7579\n",
              "2         scorer   6072\n",
              "3           game   5574\n",
              "4         season   5530\n",
              "...          ...    ...\n",
              "1078   criticism     41\n",
              "1079      praise     41\n",
              "1080       issue     41\n",
              "1081      united     41\n",
              "1082  sufficient     41\n",
              "\n",
              "[1083 rows x 2 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "FJ-eBTJWbH-r"
      },
      "outputs": [],
      "source": [
        "uw_df.to_csv(\"D:/other/Mannheim university/Data Mining/final project/additional files/words.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4R-j-FN7Rgo"
      },
      "source": [
        "# 5. Extracting the edges : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPaVj1tj9Uw6"
      },
      "source": [
        "### Step 4: Building the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt2co2ep9YCd"
      },
      "source": [
        "We are going to use the networkx library, which is a Python library that enables network science analysis of the data.\n",
        "\n",
        "We are going to use it to create our network and extract edgelist from it, since we can easily import it to Gephi (a software we are going to see in visualization labs).\n",
        "\n",
        "However, it offers implemented algorithms for analysis (for example PageRank) that you can use out-of-box to analyze your network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnd62ng6-GLW"
      },
      "source": [
        "But first, we will loop through our dataframe and connect words and hashtags if they appear together in the same Tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "adLbCz86M7SR"
      },
      "outputs": [],
      "source": [
        "uw = unique_words.keys()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "UHuQ3rRXOA5_"
      },
      "outputs": [],
      "source": [
        "network = {}\n",
        "network_key = 0\n",
        "for index, row in tweets_filtered.iterrows():\n",
        "    combined_list = [word for word in str.split(row[\"clean_text\"], \" \") if word in uw]\n",
        "    #itertool product creates Cartesian product of each element in the combined list\n",
        "    for pair in itertools.product(combined_list, combined_list):\n",
        "        #exclude self-loops and count each pair only once because our graph is undirected and we do not take self-loops into account\n",
        "        if pair[0]!=pair[1] and not(pair[::-1] in network):\n",
        "            network.setdefault(pair,0)\n",
        "            network[pair] += 1 \n",
        "    \n",
        "network_df = pd.DataFrame.from_dict(network, orient=\"index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "8uThrYGHSdEe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pair</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(also, link)</td>\n",
              "      <td>22344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(go, team)</td>\n",
              "      <td>21487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(war, also)</td>\n",
              "      <td>21246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(team, scorer)</td>\n",
              "      <td>18810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(also, r)</td>\n",
              "      <td>17724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77680</th>\n",
              "      <td>(nice, update)</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77679</th>\n",
              "      <td>(nice, bonus)</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77678</th>\n",
              "      <td>(nice, world)</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77677</th>\n",
              "      <td>(nice, cup)</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77711</th>\n",
              "      <td>(praise, win)</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77722 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 pair  weight\n",
              "0        (also, link)   22344\n",
              "1          (go, team)   21487\n",
              "2         (war, also)   21246\n",
              "3      (team, scorer)   18810\n",
              "4           (also, r)   17724\n",
              "...               ...     ...\n",
              "77680  (nice, update)      41\n",
              "77679   (nice, bonus)      41\n",
              "77678   (nice, world)      41\n",
              "77677     (nice, cup)      41\n",
              "77711   (praise, win)      41\n",
              "\n",
              "[77722 rows x 2 columns]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "network_df.reset_index(inplace=True,drop=True)\n",
        "network_df.columns = [\"pair\",\"weight\"]\n",
        "network_df.sort_values(by=\"weight\",inplace=True, ascending=False)\n",
        "network_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "NJvNvzGXy8Kg",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "\n",
        "up_weighted = []\n",
        "for edge in network:\n",
        "\n",
        "    up_weighted.append((edge[0],edge[1],network[edge]))\n",
        "\n",
        "G = nx.Graph()\n",
        "G.add_weighted_edges_from(up_weighted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "eSneLIqZNvt1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1083\n",
            "77722\n"
          ]
        }
      ],
      "source": [
        "print(len(G.nodes()))\n",
        "print(len(G.edges()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj3CwR5Cy8Kk"
      },
      "source": [
        "# 6.  Save edgelist : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "fFtpm869ONHg"
      },
      "outputs": [],
      "source": [
        "filename = \"D:/other/Mannheim university/Data Mining/final project/additional files/edgelist.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "PTmGSBc3y8Kn"
      },
      "outputs": [],
      "source": [
        "nx.write_weighted_edgelist(G, filename, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "network_df.to_csv(\"D:/other/Mannheim university/Data Mining/final project/additional files/edgelist.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5oT2lSry8Kq"
      },
      "source": [
        "# 7. Create and save node list :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "lpef5RKvUu_w"
      },
      "outputs": [],
      "source": [
        "word_nodes = pd.DataFrame.from_dict(unique_words,orient=\"index\")\n",
        "word_nodes.reset_index(inplace=True)\n",
        "word_nodes[\"Label\"] = word_nodes[\"index\"]\n",
        "word_nodes.rename(columns={\"index\":\"Id\",0:\"delete\"},inplace=True)\n",
        "word_nodes = word_nodes.drop(columns=['delete'])\n",
        "\n",
        "word_nodes\n",
        "filename = \"D:/other/Mannheim university/Data Mining/final project/additional files/nodes.csv\"\n",
        "word_nodes.to_csv(\"D:/other/Mannheim university/Data Mining/final project/additional files/nodes.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
