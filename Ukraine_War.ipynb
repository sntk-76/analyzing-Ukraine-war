{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Importing Necessary Libraries\n",
    "\n",
    "In this initial step, we import the essential Python libraries required for our project. Each library serves a specific purpose, enabling us to work with Reddit's data and perform data manipulation tasks.\n",
    "\n",
    "- **Pandas (pd)**: We use the `pandas` library to manipulate and analyze data. It's particularly well-suited for handling structured data in a tabular format, which aligns with our data analysis needs.\n",
    "\n",
    "- **PRAW (Python Reddit API Wrapper)**: For accessing Reddit's API, we utilize the `praw` library. It provides a convenient interface for interacting with Reddit, allowing us to retrieve posts, comments, and perform various actions on the platform.\n",
    "\n",
    "- **Time**: The `time` module is included to enable us to introduce controlled time delays within our code. These delays, implemented using `time.sleep()`, are essential for managing the rate at which we make requests to Reddit's API. This helps avoid overloading the API and encountering rate-limiting issues.\n",
    "\n",
    "- **PRAW Exceptions**: The `praw.exceptions` module is imported to handle specific exceptions that might arise during our interactions with Reddit's API. These exceptions include rate limit errors, connection issues, and other potential problems that could occur when retrieving data from Reddit.\n",
    "\n",
    "In summary, this initial step equips us with the necessary tools to interact with Reddit's API, fetch data, and effectively process it for analysis. We're now prepared to use these libraries in subsequent steps to retrieve and analyze data from Reddit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import time\n",
    "import praw.exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create a Reddit Application and Obtain API Credentials\n",
    "\n",
    "1. **Go to Reddit's App Preferences**:  \n",
    "   [Click here to open Reddit App Preferences](https://www.reddit.com/prefs/apps).\n",
    "\n",
    "2. **Create a New Application**:\n",
    "   - Ensure youâ€™re **logged in** to your Reddit account.\n",
    "   - Scroll down to the section titled **\"Developed Applications\"**.\n",
    "   - Click on the **\"Create App\" or \"Create Another App\"** button.\n",
    "\n",
    "3. **Fill in Application Details**:\n",
    "   - **Name**: Enter a name for your application, such as \"Reddit Data Downloader\".\n",
    "   - **App Type**: Select **\"script\"** (for personal, non-distributed use).\n",
    "   - **Description**: Write a short description (e.g., \"An app to download Reddit data\").\n",
    "   - **About URL**: Leave this blank unless you have a website for your app.\n",
    "   - **Redirect URI**: Enter a redirect URI (e.g., `http://localhost:8080`).\n",
    "   - **Permissions**: Leave as default.\n",
    "\n",
    "4. **Create the Application**:\n",
    "   - After filling in all fields, click **\"Create app\"**.\n",
    "\n",
    "5. **Retrieve Your Credentials**:\n",
    "   - **client_id**: This alphanumeric string is located directly under the application name.\n",
    "   - **client_secret**: Found in the application details and labeled as \"secret\".\n",
    "\n",
    "   Save these credentials securely, as they are needed to authenticate your API requests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Authenticating with the Reddit API\n",
    "\n",
    "To access Reddit's data programmatically, we need to authenticate our Python application using the `praw` library. Here's what each part of the code does:\n",
    "\n",
    "- `import praw`: We import the `praw` library, which is a Python wrapper for the Reddit API. This library simplifies the process of interacting with Reddit's data.\n",
    "\n",
    "- `reddit = praw.Reddit(...)`: We create a Reddit API client object named `reddit`. This object is used for making authenticated requests to the Reddit API. The constructor takes the following parameters:\n",
    "\n",
    "   - `client_id`: This should be replaced with the unique identifier of your Reddit Developer Application, which you obtained when you created the application on the Reddit Developer Portal. It's used to identify your application when making API requests.\n",
    "\n",
    "   - `client_secret`: This key should be replaced with the secret key provided during the creation of your Reddit Developer Application. It's a secret key that, when combined with the client ID, allows your application to securely authenticate with the Reddit API.\n",
    "\n",
    "   - `user_agent`: The user agent is a string that identifies your application and its purpose. It's important to provide a user agent that follows Reddit's guidelines, typically including the name of your application and a version number. For personal projects, you can include your Reddit username or any other descriptive information.\n",
    "\n",
    "With this authenticated `reddit` object, we can now access various Reddit data and perform operations like fetching posts, comments, and more, which will be an essential part of our project.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.1 of praw is outdated. Version 7.8.1 was released 6 days ago.\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id='9AkNcQ17Z5pi_zo36Qrr6g',\n",
    "    client_secret='bTQxJR7g2NVrYQZ1kNT1iipeMIGckA',\n",
    "    user_agent='Dry_Try8800',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Downloading Reddit Posts with a Keyword and Saving to CSV\n",
    "\n",
    "This code retrieves a set number of posts from Reddit that match a specific keyword (in this case, `#ukrainewar`). We save the data in a CSV file with detailed information about each post, like its title, author, and upvotes.\n",
    "\n",
    "1. **Define the Search Settings**\n",
    "   - **Subreddit**: We use `'all'`, which searches all of Reddit. You could specify a subreddit, like `'news'` or `'politics'`, to narrow down the search.\n",
    "   - **Keyword**: We set `keyword = '#ukrainewar'`, meaning weâ€™re looking for posts that contain this hashtag.\n",
    "   - **Total Posts**: We set `total_posts_to_retrieve = 1000`. This tells the code to stop once it has gathered 1,000 posts matching our criteria.\n",
    "   - **Time Filter**: We specify `time_filter = 'year'`, meaning we want posts only from the past year.\n",
    "   - **Sort Order**: We set `sort = 'top'`, which means we want the most popular posts related to our keyword.\n",
    "\n",
    "2. **Initialize an Empty List for Storing Data**\n",
    "   - We create `all_posts = []`, an empty list where we will store the data of each post. \n",
    "   - Each postâ€™s details will be stored as a dictionary in this list. This way, we can easily convert it into a DataFrame later on.\n",
    "\n",
    "3. **Download Posts in Chunks**\n",
    "   - **Why Use Chunks?**: Reddit may limit how much data you can download at once. By downloading smaller batches (or â€œchunksâ€), we avoid hitting limits or causing errors.\n",
    "   - **Setting up a Loop**: We use `remaining_posts` to track how many posts we still need. Each time we download a batch, `remaining_posts` decreases.\n",
    "   - **Chunk Size**: We define `chunk_size = min(100, remaining_posts)` to make sure each batch is no more than 100 posts. This keeps the program efficient and compatible with Reddit's limits.\n",
    "\n",
    "4. **Retrieve and Store Each Postâ€™s Data**\n",
    "   - For each batch, the code loops through each post and collects important details, like:\n",
    "     - **`subreddit`**: The subreddit where the post was published (e.g., `'politics'` or `'news'`).\n",
    "     - **`selftext`**: The main text content of the post.\n",
    "     - **`author_fullname`**: The Reddit authorâ€™s full name (if available).\n",
    "     - **`title`**: The postâ€™s title.\n",
    "     - **`upvote_ratio`** and **`ups`**: The ratio of upvotes and total upvotes the post has received.\n",
    "     - **`created`** and **`created_utc`**: The creation time of the post in both regular and UTC format.\n",
    "     - **`num_comments`**: Number of comments the post has.\n",
    "     - **`author`**: The username of the author (if available).\n",
    "     - **`id`**: The unique ID for the post.\n",
    "\n",
    "   - **Store in List**: We store each postâ€™s data as a dictionary inside `all_posts`. This makes it easy to manage and access all the post data in one place.\n",
    "\n",
    "5. **Save the Data to a CSV File**\n",
    "   - **Convert to DataFrame**: We use `pd.DataFrame(all_posts)` to convert `all_posts` into a pandas DataFrame. DataFrames are easy to work with and make it simple to save our data to a file.\n",
    "   - **Save to CSV**: The DataFrame is then saved as a CSV file using `df.to_csv('ukrainewar_full.csv', index=True)`. This file, `ukrainewar_full.csv`, now contains all the data on the posts we downloaded.\n",
    "\n",
    "6. **Print Completion Message**: Finally, the code prints `\"Data saved to 'ukrainewar_full.csv'\"` to let us know the data has been successfully saved.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example of the Code in Action\n",
    "\n",
    "Letâ€™s walk through an example to show how this code works in the first couple of loops.\n",
    "\n",
    "1. **Loop 1**: \n",
    "   - **Remaining Posts**: We start with `remaining_posts = 1000`.\n",
    "   - **Chunk Size**: Since we want 1,000 posts and can only take 100 at a time, `chunk_size = min(100, remaining_posts)` is set to 100.\n",
    "   - The code then searches for the top 100 posts with `#ukrainewar` in the last year and retrieves details for each post in that batch.\n",
    "   - **Retrieve Post Data**: For each of these posts, it gathers information like `subreddit`, `title`, `upvote_ratio`, and `author`.\n",
    "   - **Store in List**: After gathering details on each of these 100 posts, it adds them to `all_posts`.\n",
    "   - **Update Remaining Posts**: We then update `remaining_posts` to `1000 - 100 = 900`, meaning there are still 900 more posts to retrieve.\n",
    "\n",
    "2. **Loop 2**:\n",
    "   - **Remaining Posts**: Now, `remaining_posts = 900`.\n",
    "   - **Chunk Size**: Again, we retrieve another batch of 100 posts, so `chunk_size` remains 100.\n",
    "   - The code fetches another 100 posts based on the keyword, just like in Loop 1, collecting information for each post and adding it to `all_posts`.\n",
    "   - **Update Remaining Posts**: After this second batch, `remaining_posts` becomes `900 - 100 = 800`.\n",
    "\n",
    "3. **Continue the Process**:\n",
    "   - This process continues, downloading batches of 100 posts at a time, until `remaining_posts` reaches 0, meaning weâ€™ve gathered all 1,000 posts as planned.\n",
    "\n",
    "In each loop, the code:\n",
    "- Retrieves a batch of posts matching the keyword and criteria.\n",
    "- Collects important information about each post.\n",
    "- Adds that information to the main `all_posts` list.\n",
    "- Updates `remaining_posts` until we reach the target number of posts.\n",
    "\n",
    "#### Visualizing One Post\n",
    "\n",
    "Hereâ€™s what one entry in `all_posts` might look like after one post is added:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'subreddit': 'politics',\n",
    "    'selftext': 'Discussion on recent events...',\n",
    "    'author_fullname': 'user_abc',\n",
    "    'title': 'Impact of Ukraine War on Global Politics',\n",
    "    'upvote_ratio': 0.95,\n",
    "    'ups': 1500,\n",
    "    'created': 1677420800,\n",
    "    'created_utc': 1677420800,\n",
    "    'num_comments': 400,\n",
    "    'author': 'user_abc',\n",
    "    'id': 'abc123'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'ukrainewar_full.csv'\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('all')\n",
    "keyword = '#ukrainewar'\n",
    "total_posts_to_retrieve = 1000\n",
    "time_filter = 'year'\n",
    "sort = 'top'\n",
    "all_posts = []\n",
    "\n",
    "\n",
    "remaining_posts = total_posts_to_retrieve\n",
    "while remaining_posts > 0:\n",
    "    chunk_size = min(100, remaining_posts)\n",
    "    for post in subreddit.search(keyword, limit=chunk_size, time_filter=time_filter, sort=sort):\n",
    "        post_data = {\n",
    "            'subreddit': post.subreddit.display_name,\n",
    "            'selftext': post.selftext,\n",
    "            'author_fullname': post.author_fullname if post.author else 'N/A',\n",
    "            'title': post.title,\n",
    "            'upvote_ratio': post.upvote_ratio,\n",
    "            'ups': post.ups,\n",
    "            'created': post.created,\n",
    "            'created_utc': post.created_utc,\n",
    "            'num_comments': post.num_comments,\n",
    "            'author': str(post.author) if post.author else 'N/A',\n",
    "            'id': post.id\n",
    "        }\n",
    "        all_posts.append(post_data)\n",
    "\n",
    "    remaining_posts -= chunk_size\n",
    "\n",
    "\n",
    "df = pd.DataFrame(all_posts)\n",
    "df.to_csv('ukrainewar_full.csv', index=True)\n",
    "print(\"Data saved to 'ukrainewar_full.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>ups</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NonCredibleDiplomacy</td>\n",
       "      <td></td>\n",
       "      <td>t2_yjaan75u8</td>\n",
       "      <td>TIL Ukraine wantsâ€¦. Chechnya??? ðŸ¤£</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1452</td>\n",
       "      <td>1.714230e+09</td>\n",
       "      <td>1.714230e+09</td>\n",
       "      <td>93</td>\n",
       "      <td>em1011081</td>\n",
       "      <td>1cegm8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WhitePeopleTwitter</td>\n",
       "      <td></td>\n",
       "      <td>t2_5dshp</td>\n",
       "      <td>Never forget what the GOP's beloved Putin is d...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1373</td>\n",
       "      <td>1.703426e+09</td>\n",
       "      <td>1.703426e+09</td>\n",
       "      <td>36</td>\n",
       "      <td>rhino910</td>\n",
       "      <td>18pvpv6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facepalm</td>\n",
       "      <td></td>\n",
       "      <td>t2_kmlo28dhm</td>\n",
       "      <td>Russian Tools are not intelligent</td>\n",
       "      <td>0.96</td>\n",
       "      <td>655</td>\n",
       "      <td>1.712592e+09</td>\n",
       "      <td>1.712592e+09</td>\n",
       "      <td>11</td>\n",
       "      <td>Lord_Answer_me_Why</td>\n",
       "      <td>1bz1p3q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>europe</td>\n",
       "      <td>\\nThis megathread is meant for discussion of t...</td>\n",
       "      <td>t2_ojkhp</td>\n",
       "      <td>War in Ukraine Megathread LVI (57)</td>\n",
       "      <td>0.97</td>\n",
       "      <td>525</td>\n",
       "      <td>1.711113e+09</td>\n",
       "      <td>1.711113e+09</td>\n",
       "      <td>2657</td>\n",
       "      <td>ModeratorsOfEurope</td>\n",
       "      <td>1bkysju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAFO</td>\n",
       "      <td></td>\n",
       "      <td>t2_tb342</td>\n",
       "      <td>Russians in Kursk are evacuating to..... Ukraine.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>323</td>\n",
       "      <td>1.723545e+09</td>\n",
       "      <td>1.723545e+09</td>\n",
       "      <td>14</td>\n",
       "      <td>macktruck6666</td>\n",
       "      <td>1er4b5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>weapons</td>\n",
       "      <td></td>\n",
       "      <td>t2_v4ecdy4d</td>\n",
       "      <td>Russian Armed Forces Reconnaissance Units Laun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.713319e+09</td>\n",
       "      <td>1.713319e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>KyivMilitary</td>\n",
       "      <td>1c5y01u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>RAW_NEWS</td>\n",
       "      <td></td>\n",
       "      <td>t2_6nhz2unq</td>\n",
       "      <td>Charlie on Instagram: \"AMERICA ROBBED OF ITS F...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.718502e+09</td>\n",
       "      <td>1.718502e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>mrpersistence2020</td>\n",
       "      <td>1dgx0cj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>Substack</td>\n",
       "      <td>Hello, this is my Substack in which I attempt ...</td>\n",
       "      <td>t2_12lhavbzn2</td>\n",
       "      <td>Land Land Land</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.718530e+09</td>\n",
       "      <td>1.718530e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>badopinionsub</td>\n",
       "      <td>1dh3v4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>AndroidGaming</td>\n",
       "      <td>Drone game!!! #fpvdrone #ukrainewar #foryou #f...</td>\n",
       "      <td>t2_13reac5gsr</td>\n",
       "      <td>Drone incoming</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1.721465e+09</td>\n",
       "      <td>1.721465e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>monke_games_1</td>\n",
       "      <td>1e7r6vh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>AndroidGaming</td>\n",
       "      <td>Drone game!!! #fpvdrone #ukrainewar #foryou #f...</td>\n",
       "      <td>t2_13reac5gsr</td>\n",
       "      <td>Drone incoming</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1.721119e+09</td>\n",
       "      <td>1.721119e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>monke_games_1</td>\n",
       "      <td>1e4jjm3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>970 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                subreddit                                           selftext  \\\n",
       "0    NonCredibleDiplomacy                                                      \n",
       "1      WhitePeopleTwitter                                                      \n",
       "2                facepalm                                                      \n",
       "3                  europe  \\nThis megathread is meant for discussion of t...   \n",
       "4                    NAFO                                                      \n",
       "..                    ...                                                ...   \n",
       "965               weapons                                                      \n",
       "966              RAW_NEWS                                                      \n",
       "967              Substack  Hello, this is my Substack in which I attempt ...   \n",
       "968         AndroidGaming  Drone game!!! #fpvdrone #ukrainewar #foryou #f...   \n",
       "969         AndroidGaming  Drone game!!! #fpvdrone #ukrainewar #foryou #f...   \n",
       "\n",
       "    author_fullname                                              title  \\\n",
       "0      t2_yjaan75u8                  TIL Ukraine wantsâ€¦. Chechnya??? ðŸ¤£   \n",
       "1          t2_5dshp  Never forget what the GOP's beloved Putin is d...   \n",
       "2      t2_kmlo28dhm                  Russian Tools are not intelligent   \n",
       "3          t2_ojkhp                 War in Ukraine Megathread LVI (57)   \n",
       "4          t2_tb342  Russians in Kursk are evacuating to..... Ukraine.   \n",
       "..              ...                                                ...   \n",
       "965     t2_v4ecdy4d  Russian Armed Forces Reconnaissance Units Laun...   \n",
       "966     t2_6nhz2unq  Charlie on Instagram: \"AMERICA ROBBED OF ITS F...   \n",
       "967   t2_12lhavbzn2                                     Land Land Land   \n",
       "968   t2_13reac5gsr                                    Drone incoming    \n",
       "969   t2_13reac5gsr                                     Drone incoming   \n",
       "\n",
       "     upvote_ratio   ups       created   created_utc  num_comments  \\\n",
       "0            0.98  1452  1.714230e+09  1.714230e+09            93   \n",
       "1            0.97  1373  1.703426e+09  1.703426e+09            36   \n",
       "2            0.96   655  1.712592e+09  1.712592e+09            11   \n",
       "3            0.97   525  1.711113e+09  1.711113e+09          2657   \n",
       "4            1.00   323  1.723545e+09  1.723545e+09            14   \n",
       "..            ...   ...           ...           ...           ...   \n",
       "965          0.50     0  1.713319e+09  1.713319e+09             0   \n",
       "966          0.50     0  1.718502e+09  1.718502e+09             0   \n",
       "967          0.33     0  1.718530e+09  1.718530e+09             0   \n",
       "968          0.38     0  1.721465e+09  1.721465e+09             1   \n",
       "969          0.35     0  1.721119e+09  1.721119e+09             4   \n",
       "\n",
       "                 author       id  \n",
       "0             em1011081  1cegm8c  \n",
       "1              rhino910  18pvpv6  \n",
       "2    Lord_Answer_me_Why  1bz1p3q  \n",
       "3    ModeratorsOfEurope  1bkysju  \n",
       "4         macktruck6666  1er4b5b  \n",
       "..                  ...      ...  \n",
       "965        KyivMilitary  1c5y01u  \n",
       "966   mrpersistence2020  1dgx0cj  \n",
       "967       badopinionsub  1dh3v4b  \n",
       "968       monke_games_1  1e7r6vh  \n",
       "969       monke_games_1  1e4jjm3  \n",
       "\n",
       "[970 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Data Processing and Deduplication\n",
    "\n",
    "1. **Create a Copy of the DataFrame**:  \n",
    "   - A copy of the original DataFrame `df` is created to work with, ensuring that the original data remains unchanged.\n",
    "\n",
    "2. **Sort the Data by Number of Comments**:  \n",
    "   - The DataFrame is sorted in descending order based on the number of comments, so posts with more comments appear first. This helps keep the most engaged posts when removing duplicates.\n",
    "\n",
    "3. **Remove Duplicate Posts by Post ID**:  \n",
    "   - Duplicate posts are removed based on the unique `id` of each post. Only the first occurrence of each `id` (with the most comments due to the sorting) is retained.\n",
    "\n",
    "4. **Reset the DataFrame Index**:  \n",
    "   - The DataFrame index is reset to ensure it is sequential, starting from 0. Dropping the old index keeps the DataFrame clean.\n",
    "\n",
    "5. **Display the Cleaned DataFrame**:  \n",
    "   - The final result, `unique_posts`, is displayed, containing only unique posts with the highest engagement (by comments).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>ups</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe</td>\n",
       "      <td>\\nThis megathread is meant for discussion of t...</td>\n",
       "      <td>t2_ojkhp</td>\n",
       "      <td>War in Ukraine Megathread LVI (57)</td>\n",
       "      <td>0.97</td>\n",
       "      <td>529</td>\n",
       "      <td>1.711113e+09</td>\n",
       "      <td>1.711113e+09</td>\n",
       "      <td>2657</td>\n",
       "      <td>ModeratorsOfEurope</td>\n",
       "      <td>1bkysju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>europe</td>\n",
       "      <td>\\nThis megathread is meant for discussion of t...</td>\n",
       "      <td>t2_7b6qg</td>\n",
       "      <td>War in Ukraine Megathread LVIII (58)</td>\n",
       "      <td>0.94</td>\n",
       "      <td>88</td>\n",
       "      <td>1.726737e+09</td>\n",
       "      <td>1.726737e+09</td>\n",
       "      <td>454</td>\n",
       "      <td>BkkGrl</td>\n",
       "      <td>1fkglfj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NonCredibleDiplomacy</td>\n",
       "      <td></td>\n",
       "      <td>t2_yjaan75u8</td>\n",
       "      <td>TIL Ukraine wantsâ€¦. Chechnya??? ðŸ¤£</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1448</td>\n",
       "      <td>1.714230e+09</td>\n",
       "      <td>1.714230e+09</td>\n",
       "      <td>93</td>\n",
       "      <td>em1011081</td>\n",
       "      <td>1cegm8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600euro</td>\n",
       "      <td></td>\n",
       "      <td>t2_il63lzpcx</td>\n",
       "      <td>FÃ¤ngt die Ampel wohl bald einen Krieg an?</td>\n",
       "      <td>0.99</td>\n",
       "      <td>180</td>\n",
       "      <td>1.709498e+09</td>\n",
       "      <td>1.709498e+09</td>\n",
       "      <td>80</td>\n",
       "      <td>Meaglo</td>\n",
       "      <td>1b5rdjk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indonesia</td>\n",
       "      <td></td>\n",
       "      <td>t2_bywstnsf</td>\n",
       "      <td>What? Tribun is evolving! English video + robo...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>180</td>\n",
       "      <td>1.711219e+09</td>\n",
       "      <td>1.711219e+09</td>\n",
       "      <td>45</td>\n",
       "      <td>Affectionate_Cat293</td>\n",
       "      <td>1blzh0r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Standbyukraine</td>\n",
       "      <td>https://preview.redd.it/f5rhpblge4td1.jpg?widt...</td>\n",
       "      <td>t2_fneqj99c</td>\n",
       "      <td>Will Western Leaders Choose Appeasement or Res...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.728214e+09</td>\n",
       "      <td>1.728214e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>ChristianEnglev</td>\n",
       "      <td>1fxe9sk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>yUkraine</td>\n",
       "      <td></td>\n",
       "      <td>t2_u42z2</td>\n",
       "      <td>Beautiful architecture in Ukraine Ivano-Franki...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.718478e+09</td>\n",
       "      <td>1.718478e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Lodhur</td>\n",
       "      <td>1dgp32s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>yUkraine</td>\n",
       "      <td></td>\n",
       "      <td>t2_u42z2</td>\n",
       "      <td>the graveyard #ukraine #memorialday #holiday #...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.717249e+09</td>\n",
       "      <td>1.717249e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Lodhur</td>\n",
       "      <td>1d5n9eq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>u_Mriya_Production</td>\n",
       "      <td>ðŸ‡ºðŸ‡¦ Immerse yourself in the resilience of war-t...</td>\n",
       "      <td>t2_qpqn0lxe3</td>\n",
       "      <td>Murals, a documentary featuring Banksy's works...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.704753e+09</td>\n",
       "      <td>1.704753e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Mriya_Production</td>\n",
       "      <td>191xz1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>u_monke_games_1</td>\n",
       "      <td>Drone game!!! #fpvdrone #ukrainewar #foryou #f...</td>\n",
       "      <td>t2_13reac5gsr</td>\n",
       "      <td>Drone incoming</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1.721062e+09</td>\n",
       "      <td>1.721062e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>monke_games_1</td>\n",
       "      <td>1e3zjh4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               subreddit                                           selftext  \\\n",
       "0                 europe  \\nThis megathread is meant for discussion of t...   \n",
       "1                 europe  \\nThis megathread is meant for discussion of t...   \n",
       "2   NonCredibleDiplomacy                                                      \n",
       "3                600euro                                                      \n",
       "4              indonesia                                                      \n",
       "..                   ...                                                ...   \n",
       "92        Standbyukraine  https://preview.redd.it/f5rhpblge4td1.jpg?widt...   \n",
       "93              yUkraine                                                      \n",
       "94              yUkraine                                                      \n",
       "95    u_Mriya_Production  ðŸ‡ºðŸ‡¦ Immerse yourself in the resilience of war-t...   \n",
       "96       u_monke_games_1  Drone game!!! #fpvdrone #ukrainewar #foryou #f...   \n",
       "\n",
       "   author_fullname                                              title  \\\n",
       "0         t2_ojkhp                 War in Ukraine Megathread LVI (57)   \n",
       "1         t2_7b6qg               War in Ukraine Megathread LVIII (58)   \n",
       "2     t2_yjaan75u8                  TIL Ukraine wantsâ€¦. Chechnya??? ðŸ¤£   \n",
       "3     t2_il63lzpcx          FÃ¤ngt die Ampel wohl bald einen Krieg an?   \n",
       "4      t2_bywstnsf  What? Tribun is evolving! English video + robo...   \n",
       "..             ...                                                ...   \n",
       "92     t2_fneqj99c  Will Western Leaders Choose Appeasement or Res...   \n",
       "93        t2_u42z2  Beautiful architecture in Ukraine Ivano-Franki...   \n",
       "94        t2_u42z2  the graveyard #ukraine #memorialday #holiday #...   \n",
       "95    t2_qpqn0lxe3  Murals, a documentary featuring Banksy's works...   \n",
       "96   t2_13reac5gsr                                     Drone incoming   \n",
       "\n",
       "    upvote_ratio   ups       created   created_utc  num_comments  \\\n",
       "0           0.97   529  1.711113e+09  1.711113e+09          2657   \n",
       "1           0.94    88  1.726737e+09  1.726737e+09           454   \n",
       "2           0.98  1448  1.714230e+09  1.714230e+09            93   \n",
       "3           0.99   180  1.709498e+09  1.709498e+09            80   \n",
       "4           0.95   180  1.711219e+09  1.711219e+09            45   \n",
       "..           ...   ...           ...           ...           ...   \n",
       "92          1.00     1  1.728214e+09  1.728214e+09             0   \n",
       "93          1.00     1  1.718478e+09  1.718478e+09             0   \n",
       "94          1.00     1  1.717249e+09  1.717249e+09             0   \n",
       "95          1.00     1  1.704753e+09  1.704753e+09             0   \n",
       "96          0.66     1  1.721062e+09  1.721062e+09             0   \n",
       "\n",
       "                 author       id  \n",
       "0    ModeratorsOfEurope  1bkysju  \n",
       "1                BkkGrl  1fkglfj  \n",
       "2             em1011081  1cegm8c  \n",
       "3                Meaglo  1b5rdjk  \n",
       "4   Affectionate_Cat293  1blzh0r  \n",
       "..                  ...      ...  \n",
       "92      ChristianEnglev  1fxe9sk  \n",
       "93               Lodhur  1dgp32s  \n",
       "94               Lodhur  1d5n9eq  \n",
       "95     Mriya_Production  191xz1a  \n",
       "96        monke_games_1  1e3zjh4  \n",
       "\n",
       "[97 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_posts = df.copy()\n",
    "unique_posts.sort_values(by='num_comments',ascending=False,inplace=True)\n",
    "unique_posts.drop_duplicates(subset='id',inplace=True)\n",
    "unique_posts.reset_index(inplace=True,drop=True)\n",
    "unique_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Extracting Comments for Reddit Posts\n",
    "\n",
    "This code snippet outlines the process of extracting comments related to Reddit posts. It utilizes the Python Reddit API Wrapper (PRAW) library and the information obtained from the previous steps. The explanation of the code is as follows:\n",
    "\n",
    "1. **Empty List Creation**: An empty list named `comments_list` is initialized. This list will be used to store extracted comment data.\n",
    "\n",
    "2. **Comment Extraction Function**: The code defines a function called `extract_comments(post_id)`. This function takes a post's unique identifier (`post_id`) as a parameter.\n",
    "\n",
    "3. **Reddit Submission Retrieval**: Within the function, a Reddit post submission is retrieved using the provided `post_id`. This submission object represents the specific post on Reddit.\n",
    "\n",
    "4. **Replacing More Comments**: To ensure all comments are retrieved, the code uses `submission.comments.replace_more(limit=None)` to replace more comments. This is necessary because Reddit employs a \"load more comments\" mechanism that can hide some comments from direct retrieval. This function effectively retrieves all comments.\n",
    "\n",
    "5. **Comment Data Extraction**: The code then iterates through the comments using a list comprehension. For each comment, it extracts three pieces of information: the `comment_id` (unique comment identifier), `comment_body` (the text content of the comment), and `post_id` (the identifier of the post to which the comment is related). These details are stored in a dictionary.\n",
    "\n",
    "6. **Appending to `comments_list`**: The extracted comment data is appended to the `comments_list` as a dictionary. This process ensures that comments from multiple posts are gathered in a single list for later analysis.\n",
    "\n",
    "By using this code, you can collect comments related to Reddit posts, making them available for further processing and analysis. Each comment is associated with its parent post, which can be valuable for understanding user engagement and sentiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_list = []\n",
    "\n",
    "def extract_comments(post_id):\n",
    "    submission = reddit.submission(id=post_id)\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    comments_list.extend([{'comment_id': comment.id,'comment_body': comment.body,'post_id': post_id,} for comment in submission.comments.list()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Extracting Comments from Reddit Posts\n",
    "\n",
    "In this code block, we see the process of extracting comments from Reddit posts. The code is designed to handle potential rate limiting by Reddit's API while collecting the comments. Here's a step-by-step explanation of the code:\n",
    "\n",
    "1. **Iteration Through Posts**: The code starts by initializing a variable `i` to zero. It then iterates through the unique post identifiers stored in the DataFrame `unique_posts` using the 'id' column.\n",
    "\n",
    "2. **Rate Limit Handling**: Within the loop, the code includes a rate limit handling mechanism. The code checks if `i` (the rate limit counter) is less than 5, indicating that we will attempt to collect comments from up to four posts.\n",
    "\n",
    "3. **Try-Except Block**: Inside the loop, there's a try-except block. It attempts to extract comments from a Reddit post using the `extract_comments` function. If there's an exception (such as reaching the rate limit), the code proceeds to the except block.\n",
    "\n",
    "4. **Rate Limit Exceeded Handling**: In the except block, `i` is incremented by 1, indicating that an attempt to collect comments has been made. The code also prints an informative message indicating that the rate limit was exceeded and that it's waiting for a moment before retrying. A delay of 7 seconds (achieved using `time.sleep(7)`) is introduced to prevent overwhelming the Reddit API with requests.\n",
    "\n",
    "5. **Continuing the Loop**: After handling the exception, the code continues the loop to try collecting comments from the next post. This process repeats up to four times (controlled by the rate limit handling).\n",
    "\n",
    "6. **Creating a DataFrame**: After the loop completes, a DataFrame named `comments_df` is created. This DataFrame is built from the `comments_list`, which accumulates comments from multiple posts. Each row in the DataFrame represents a comment, including the `comment_id`, `comment_body`, and `post_id`.\n",
    "\n",
    "7. **Saving to CSV**: Finally, the DataFrame is saved to a CSV file named 'comments_data.csv' without an index column.\n",
    "\n",
    "By using this code, you can systematically extract comments from multiple Reddit posts while efficiently handling rate limits, making it suitable for data collection tasks that involve Reddit's API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for post_id in unique_posts['id']:\n",
    "    print(i)\n",
    "\n",
    "    if i < 5: \n",
    "        try:\n",
    "            extract_comments(post_id)\n",
    "        except Exception as error:\n",
    "            i += 1\n",
    "            print(f\"Rate limit exceeded. Waiting for a moment. Error: {error}\")\n",
    "            time.sleep(7)\n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "comments_df = pd.DataFrame(comments_list)\n",
    "\n",
    "\n",
    "comments_df.to_csv('comments_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kw230q6</td>\n",
       "      <td>The latest round of missile strikes on Ukraine...</td>\n",
       "      <td>1bkysju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kz1n390</td>\n",
       "      <td>I'm so fucking tired of Europe being afraid of...</td>\n",
       "      <td>1bkysju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kw6apo1</td>\n",
       "      <td>It's really an extraordinary moment: we have a...</td>\n",
       "      <td>1bkysju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kwt3o1a</td>\n",
       "      <td>Russian propaganda in Serbia's government-spon...</td>\n",
       "      <td>1bkysju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lh6von7</td>\n",
       "      <td>Apparently, one of the units participating in ...</td>\n",
       "      <td>1bkysju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>li7m0a9</td>\n",
       "      <td>Thanks for posting on r/YouTubePromoter!\\n\\n*I...</td>\n",
       "      <td>1esqde2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>kho66ig</td>\n",
       "      <td>Bard's response to this inquiry: \"What does sc...</td>\n",
       "      <td>195p8ey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>lpgmbkt</td>\n",
       "      <td>PTSD angry birds</td>\n",
       "      <td>1e7r726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>le239io</td>\n",
       "      <td>What are those hashtags bruh</td>\n",
       "      <td>1e7r6vh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>kzxch4h</td>\n",
       "      <td>Join our community at tuckercarlson(dot)win.\\n...</td>\n",
       "      <td>1c5xzat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     comment_id                                       comment_body  post_id\n",
       "0       kw230q6  The latest round of missile strikes on Ukraine...  1bkysju\n",
       "1       kz1n390  I'm so fucking tired of Europe being afraid of...  1bkysju\n",
       "2       kw6apo1  It's really an extraordinary moment: we have a...  1bkysju\n",
       "3       kwt3o1a  Russian propaganda in Serbia's government-spon...  1bkysju\n",
       "4       lh6von7  Apparently, one of the units participating in ...  1bkysju\n",
       "...         ...                                                ...      ...\n",
       "3271    li7m0a9  Thanks for posting on r/YouTubePromoter!\\n\\n*I...  1esqde2\n",
       "3272    kho66ig  Bard's response to this inquiry: \"What does sc...  195p8ey\n",
       "3273    lpgmbkt                                   PTSD angry birds  1e7r726\n",
       "3274    le239io                       What are those hashtags bruh  1e7r6vh\n",
       "3275    kzxch4h  Join our community at tuckercarlson(dot)win.\\n...  1c5xzat\n",
       "\n",
       "[3276 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = pd.read_csv('comments_data.csv')\n",
    "comments_df = pd.DataFrame(comments_df)\n",
    "comments_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
